<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.8"/>
<title>Caffe: caffe::SigmoidCrossEntropyLossLayer&lt; Dtype &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Caffe
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.8 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
      <li><a href="hierarchy.html"><span>Class&#160;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&#160;Members</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Variables</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>caffe</b></li><li class="navelem"><a class="el" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html">SigmoidCrossEntropyLossLayer</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="classcaffe_1_1SigmoidCrossEntropyLossLayer-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">caffe::SigmoidCrossEntropyLossLayer&lt; Dtype &gt; Class Template Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Computes the cross-entropy (logistic) loss <img class="formulaInl" alt="$ E = \frac{-1}{n} \sum\limits_{n=1}^N \left[ p_n \log \hat{p}_n + (1 - p_n) \log(1 - \hat{p}_n) \right] $" src="form_57.png"/>, often used for predicting targets interpreted as probabilities.  
 <a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="loss__layers_8hpp_source.html">loss_layers.hpp</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for caffe::SigmoidCrossEntropyLossLayer&lt; Dtype &gt;:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classcaffe_1_1SigmoidCrossEntropyLossLayer.png" usemap="#caffe::SigmoidCrossEntropyLossLayer&lt; Dtype &gt;_map" alt=""/>
  <map id="caffe::SigmoidCrossEntropyLossLayer&lt; Dtype &gt;_map" name="caffe::SigmoidCrossEntropyLossLayer&lt; Dtype &gt;_map">
<area href="classcaffe_1_1LossLayer.html" title="An interface for Layers that take two Blobs as input â€“ usually (1) predictions and (2) ground-truth ..." alt="caffe::LossLayer&lt; Dtype &gt;" shape="rect" coords="0,56,284,80"/>
<area href="classcaffe_1_1Layer.html" title="An interface for the units of computation which can be composed into a Net. " alt="caffe::Layer&lt; Dtype &gt;" shape="rect" coords="0,0,284,24"/>
</map>
 </div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a3b4478b3d5c5130de685b240b274c06c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3b4478b3d5c5130de685b240b274c06c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>SigmoidCrossEntropyLossLayer</b> (const LayerParameter &amp;param)</td></tr>
<tr class="separator:a3b4478b3d5c5130de685b240b274c06c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a995f9869f2167df152cdec773b53bd90"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a995f9869f2167df152cdec773b53bd90">LayerSetUp</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; *top)</td></tr>
<tr class="memdesc:a995f9869f2167df152cdec773b53bd90"><td class="mdescLeft">&#160;</td><td class="mdescRight">Does layer-specific setup: your layer should implement this.  <a href="#a995f9869f2167df152cdec773b53bd90">More...</a><br /></td></tr>
<tr class="separator:a995f9869f2167df152cdec773b53bd90"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79f3344dc486d27da32d017bf35fe458"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a79f3344dc486d27da32d017bf35fe458"></a>
virtual LayerParameter_LayerType&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a79f3344dc486d27da32d017bf35fe458">type</a> () const </td></tr>
<tr class="memdesc:a79f3344dc486d27da32d017bf35fe458"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the layer type as an enum value. <br /></td></tr>
<tr class="separator:a79f3344dc486d27da32d017bf35fe458"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classcaffe_1_1LossLayer"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classcaffe_1_1LossLayer')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classcaffe_1_1LossLayer.html">caffe::LossLayer&lt; Dtype &gt;</a></td></tr>
<tr class="memitem:a16e133050e2d97c6f024ea74e3ba4ead inherit pub_methods_classcaffe_1_1LossLayer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a16e133050e2d97c6f024ea74e3ba4ead"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>LossLayer</b> (const LayerParameter &amp;param)</td></tr>
<tr class="separator:a16e133050e2d97c6f024ea74e3ba4ead inherit pub_methods_classcaffe_1_1LossLayer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8a2e16d4691640c34e589aac4ec42e28 inherit pub_methods_classcaffe_1_1LossLayer"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1LossLayer.html#a8a2e16d4691640c34e589aac4ec42e28">ExactNumBottomBlobs</a> () const </td></tr>
<tr class="memdesc:a8a2e16d4691640c34e589aac4ec42e28 inherit pub_methods_classcaffe_1_1LossLayer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required.  <a href="#a8a2e16d4691640c34e589aac4ec42e28">More...</a><br /></td></tr>
<tr class="separator:a8a2e16d4691640c34e589aac4ec42e28 inherit pub_methods_classcaffe_1_1LossLayer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad272e6792a781ce4f66a65057cc829d1 inherit pub_methods_classcaffe_1_1LossLayer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad272e6792a781ce4f66a65057cc829d1"></a>
virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1LossLayer.html#ad272e6792a781ce4f66a65057cc829d1">AutoTopBlobs</a> () const </td></tr>
<tr class="memdesc:ad272e6792a781ce4f66a65057cc829d1 inherit pub_methods_classcaffe_1_1LossLayer"><td class="mdescLeft">&#160;</td><td class="mdescRight">For convenience and backwards compatibility, instruct the <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a> to automatically allocate a single top <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> for LossLayers, into which they output their singleton loss, (even if the user didn't specify one in the prototxt, etc.). <br /></td></tr>
<tr class="separator:ad272e6792a781ce4f66a65057cc829d1 inherit pub_methods_classcaffe_1_1LossLayer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af8dca16967e8e979ebead4e80664dc10 inherit pub_methods_classcaffe_1_1LossLayer"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1LossLayer.html#af8dca16967e8e979ebead4e80664dc10">ExactNumTopBlobs</a> () const </td></tr>
<tr class="memdesc:af8dca16967e8e979ebead4e80664dc10 inherit pub_methods_classcaffe_1_1LossLayer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required.  <a href="#af8dca16967e8e979ebead4e80664dc10">More...</a><br /></td></tr>
<tr class="separator:af8dca16967e8e979ebead4e80664dc10 inherit pub_methods_classcaffe_1_1LossLayer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad02fe695b06451ac8e6f21db0cba1dad inherit pub_methods_classcaffe_1_1LossLayer"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1LossLayer.html#ad02fe695b06451ac8e6f21db0cba1dad">AllowForceBackward</a> (const int bottom_index) const </td></tr>
<tr class="separator:ad02fe695b06451ac8e6f21db0cba1dad inherit pub_methods_classcaffe_1_1LossLayer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classcaffe_1_1Layer"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classcaffe_1_1Layer')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classcaffe_1_1Layer.html">caffe::Layer&lt; Dtype &gt;</a></td></tr>
<tr class="memitem:a7b4e4ccea08c7b8b15acc6829d5735f6 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a7b4e4ccea08c7b8b15acc6829d5735f6">Layer</a> (const LayerParameter &amp;param)</td></tr>
<tr class="separator:a7b4e4ccea08c7b8b15acc6829d5735f6 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f7809d8e708c4408a96af0752aec481 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a4f7809d8e708c4408a96af0752aec481">SetUp</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; *top)</td></tr>
<tr class="memdesc:a4f7809d8e708c4408a96af0752aec481 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implements common layer setup functionality.  <a href="#a4f7809d8e708c4408a96af0752aec481">More...</a><br /></td></tr>
<tr class="separator:a4f7809d8e708c4408a96af0752aec481 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a31d00947960a1334be6e45c9a43d8d58 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">Dtype&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a31d00947960a1334be6e45c9a43d8d58">Forward</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; *top)</td></tr>
<tr class="memdesc:a31d00947960a1334be6e45c9a43d8d58 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given the bottom blobs, compute the top blobs and the loss.  <a href="#a31d00947960a1334be6e45c9a43d8d58">More...</a><br /></td></tr>
<tr class="separator:a31d00947960a1334be6e45c9a43d8d58 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38823aa5348f83afd589ec3ac954657e inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a38823aa5348f83afd589ec3ac954657e">Backward</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; *bottom)</td></tr>
<tr class="memdesc:a38823aa5348f83afd589ec3ac954657e inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given the top blob error gradients, compute the bottom blob error gradients.  <a href="#a38823aa5348f83afd589ec3ac954657e">More...</a><br /></td></tr>
<tr class="separator:a38823aa5348f83afd589ec3ac954657e inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf4524ce8641a30a8a4784aee1b2b4c8 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaf4524ce8641a30a8a4784aee1b2b4c8"></a>
vector&lt; shared_ptr&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a><br class="typebreak" />
&lt; Dtype &gt; &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#aaf4524ce8641a30a8a4784aee1b2b4c8">blobs</a> ()</td></tr>
<tr class="memdesc:aaf4524ce8641a30a8a4784aee1b2b4c8 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the vector of learnable parameter blobs. <br /></td></tr>
<tr class="separator:aaf4524ce8641a30a8a4784aee1b2b4c8 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af475062fe280614b18f642c4ccf50b40 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af475062fe280614b18f642c4ccf50b40"></a>
const LayerParameter &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#af475062fe280614b18f642c4ccf50b40">layer_param</a> () const </td></tr>
<tr class="memdesc:af475062fe280614b18f642c4ccf50b40 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the layer parameter. <br /></td></tr>
<tr class="separator:af475062fe280614b18f642c4ccf50b40 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a1754828dda22cc8daa2f63377f3579 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4a1754828dda22cc8daa2f63377f3579"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a4a1754828dda22cc8daa2f63377f3579">ToProto</a> (LayerParameter *param, bool write_diff=false)</td></tr>
<tr class="memdesc:a4a1754828dda22cc8daa2f63377f3579 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Writes the layer parameter to a protocol buffer. <br /></td></tr>
<tr class="separator:a4a1754828dda22cc8daa2f63377f3579 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a964ccba33b9a4b69391a72508f764eaf inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a964ccba33b9a4b69391a72508f764eaf"></a>
Dtype&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a964ccba33b9a4b69391a72508f764eaf">loss</a> (const int top_index) const </td></tr>
<tr class="memdesc:a964ccba33b9a4b69391a72508f764eaf inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the scalar loss associated with a top blob at a given index. <br /></td></tr>
<tr class="separator:a964ccba33b9a4b69391a72508f764eaf inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a899b09f4b91ada8545b3a43ee91e0d69 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a899b09f4b91ada8545b3a43ee91e0d69"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a899b09f4b91ada8545b3a43ee91e0d69">set_loss</a> (const int top_index, const Dtype value)</td></tr>
<tr class="memdesc:a899b09f4b91ada8545b3a43ee91e0d69 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the loss associated with a top blob at a given index. <br /></td></tr>
<tr class="separator:a899b09f4b91ada8545b3a43ee91e0d69 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a29dba205196d9aeaa1cfeba4dc891093 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a29dba205196d9aeaa1cfeba4dc891093"></a>
virtual const string &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a29dba205196d9aeaa1cfeba4dc891093">type_name</a> () const </td></tr>
<tr class="memdesc:a29dba205196d9aeaa1cfeba4dc891093 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the layer type name. <br /></td></tr>
<tr class="separator:a29dba205196d9aeaa1cfeba4dc891093 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade3eee97cc743c4e68fff7eba6484916 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#ade3eee97cc743c4e68fff7eba6484916">MinBottomBlobs</a> () const </td></tr>
<tr class="memdesc:ade3eee97cc743c4e68fff7eba6484916 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the minimum number of bottom blobs required by the layer, or -1 if no minimum number is required.  <a href="#ade3eee97cc743c4e68fff7eba6484916">More...</a><br /></td></tr>
<tr class="separator:ade3eee97cc743c4e68fff7eba6484916 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6408ef3939f1abed1abcec46ff219289 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a6408ef3939f1abed1abcec46ff219289">MaxBottomBlobs</a> () const </td></tr>
<tr class="memdesc:a6408ef3939f1abed1abcec46ff219289 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the maximum number of bottom blobs required by the layer, or -1 if no maximum number is required.  <a href="#a6408ef3939f1abed1abcec46ff219289">More...</a><br /></td></tr>
<tr class="separator:a6408ef3939f1abed1abcec46ff219289 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8bb143d58a740345fa2dc3d4204d553b inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a8bb143d58a740345fa2dc3d4204d553b">MinTopBlobs</a> () const </td></tr>
<tr class="memdesc:a8bb143d58a740345fa2dc3d4204d553b inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the minimum number of top blobs required by the layer, or -1 if no minimum number is required.  <a href="#a8bb143d58a740345fa2dc3d4204d553b">More...</a><br /></td></tr>
<tr class="separator:a8bb143d58a740345fa2dc3d4204d553b inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adeff774663c6ec94424901d2746e2f03 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#adeff774663c6ec94424901d2746e2f03">MaxTopBlobs</a> () const </td></tr>
<tr class="memdesc:adeff774663c6ec94424901d2746e2f03 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the maximum number of top blobs required by the layer, or -1 if no maximum number is required.  <a href="#adeff774663c6ec94424901d2746e2f03">More...</a><br /></td></tr>
<tr class="separator:adeff774663c6ec94424901d2746e2f03 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad412187a0483c310bd59fd5f957faf0d inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#ad412187a0483c310bd59fd5f957faf0d">EqualNumBottomTopBlobs</a> () const </td></tr>
<tr class="memdesc:ad412187a0483c310bd59fd5f957faf0d inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns true if the layer requires an equal number of bottom and top blobs.  <a href="#ad412187a0483c310bd59fd5f957faf0d">More...</a><br /></td></tr>
<tr class="separator:ad412187a0483c310bd59fd5f957faf0d inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1a3708013b0231e71d725252e10ce6e3 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a1a3708013b0231e71d725252e10ce6e3">param_propagate_down</a> (const int param_id)</td></tr>
<tr class="memdesc:a1a3708013b0231e71d725252e10ce6e3 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Specifies whether the layer should compute gradients w.r.t. a parameter at a particular index given by param_id.  <a href="#a1a3708013b0231e71d725252e10ce6e3">More...</a><br /></td></tr>
<tr class="separator:a1a3708013b0231e71d725252e10ce6e3 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a6fcb843803ed556f0a69cc2864379b inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9a6fcb843803ed556f0a69cc2864379b"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a9a6fcb843803ed556f0a69cc2864379b">set_param_propagate_down</a> (const int param_id, const bool value)</td></tr>
<tr class="memdesc:a9a6fcb843803ed556f0a69cc2864379b inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets whether the layer should compute gradients w.r.t. a parameter at a particular index given by param_id. <br /></td></tr>
<tr class="separator:a9a6fcb843803ed556f0a69cc2864379b inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:aaf5a9f893661766ca7987ed748027e41"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#aaf5a9f893661766ca7987ed748027e41">Forward_cpu</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; *top)</td></tr>
<tr class="memdesc:aaf5a9f893661766ca7987ed748027e41"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the cross-entropy (logistic) loss <img class="formulaInl" alt="$ E = \frac{-1}{n} \sum\limits_{n=1}^N \left[ p_n \log \hat{p}_n + (1 - p_n) \log(1 - \hat{p}_n) \right] $" src="form_57.png"/>, often used for predicting targets interpreted as probabilities.  <a href="#aaf5a9f893661766ca7987ed748027e41">More...</a><br /></td></tr>
<tr class="separator:aaf5a9f893661766ca7987ed748027e41"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac62d50044f3fdcc9915a03dffb2eca40"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac62d50044f3fdcc9915a03dffb2eca40"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#ac62d50044f3fdcc9915a03dffb2eca40">Forward_gpu</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; *top)</td></tr>
<tr class="memdesc:ac62d50044f3fdcc9915a03dffb2eca40"><td class="mdescLeft">&#160;</td><td class="mdescRight">Using the GPU device, compute the layer output. Fall back to <a class="el" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#aaf5a9f893661766ca7987ed748027e41" title="Computes the cross-entropy (logistic) loss , often used for predicting targets interpreted as probabi...">Forward_cpu()</a> if unavailable. <br /></td></tr>
<tr class="separator:ac62d50044f3fdcc9915a03dffb2eca40"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af43a48c97cfcc6c3339f99e802797c8d"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#af43a48c97cfcc6c3339f99e802797c8d">Backward_cpu</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; *bottom)</td></tr>
<tr class="memdesc:af43a48c97cfcc6c3339f99e802797c8d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the sigmoid cross-entropy loss error gradient w.r.t. the predictions.  <a href="#af43a48c97cfcc6c3339f99e802797c8d">More...</a><br /></td></tr>
<tr class="separator:af43a48c97cfcc6c3339f99e802797c8d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab9de1575463555e4339082b5ad7306b4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab9de1575463555e4339082b5ad7306b4"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#ab9de1575463555e4339082b5ad7306b4">Backward_gpu</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; *bottom)</td></tr>
<tr class="memdesc:ab9de1575463555e4339082b5ad7306b4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_down is true. Fall back to <a class="el" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#af43a48c97cfcc6c3339f99e802797c8d" title="Computes the sigmoid cross-entropy loss error gradient w.r.t. the predictions. ">Backward_cpu()</a> if unavailable. <br /></td></tr>
<tr class="separator:ab9de1575463555e4339082b5ad7306b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_methods_classcaffe_1_1Layer"><td colspan="2" onclick="javascript:toggleInherit('pro_methods_classcaffe_1_1Layer')"><img src="closed.png" alt="-"/>&#160;Protected Member Functions inherited from <a class="el" href="classcaffe_1_1Layer.html">caffe::Layer&lt; Dtype &gt;</a></td></tr>
<tr class="memitem:adaa95e30dff155409a25ffcb5c8c885e inherit pro_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#adaa95e30dff155409a25ffcb5c8c885e">CheckBlobCounts</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;top)</td></tr>
<tr class="separator:adaa95e30dff155409a25ffcb5c8c885e inherit pro_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5bebaf079cff5bff7016be1733bb996e inherit pro_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a5bebaf079cff5bff7016be1733bb996e">SetLossWeights</a> (vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; *top)</td></tr>
<tr class="separator:a5bebaf079cff5bff7016be1733bb996e inherit pro_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a90730e177e4b3b3516b1b69ba2f6b06a inherit pro_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a90730e177e4b3b3516b1b69ba2f6b06a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>DISABLE_COPY_AND_ASSIGN</b> (<a class="el" href="classcaffe_1_1Layer.html">Layer</a>)</td></tr>
<tr class="separator:a90730e177e4b3b3516b1b69ba2f6b06a inherit pro_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:a69e0c8d2106b4b06c7c896e3069f531c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a69e0c8d2106b4b06c7c896e3069f531c"></a>
shared_ptr&lt; <a class="el" href="classcaffe_1_1SigmoidLayer.html">SigmoidLayer</a>&lt; Dtype &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a69e0c8d2106b4b06c7c896e3069f531c">sigmoid_layer_</a></td></tr>
<tr class="memdesc:a69e0c8d2106b4b06c7c896e3069f531c"><td class="mdescLeft">&#160;</td><td class="mdescRight">The internal <a class="el" href="classcaffe_1_1SigmoidLayer.html" title="Sigmoid function non-linearity , a classic choice in neural networks. ">SigmoidLayer</a> used to map predictions to probabilities. <br /></td></tr>
<tr class="separator:a69e0c8d2106b4b06c7c896e3069f531c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1eb4c2e90dd4807dbfb0806a411a7bea"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a1eb4c2e90dd4807dbfb0806a411a7bea"></a>
shared_ptr&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a1eb4c2e90dd4807dbfb0806a411a7bea">sigmoid_output_</a></td></tr>
<tr class="memdesc:a1eb4c2e90dd4807dbfb0806a411a7bea"><td class="mdescLeft">&#160;</td><td class="mdescRight">sigmoid_output stores the output of the <a class="el" href="classcaffe_1_1SigmoidLayer.html" title="Sigmoid function non-linearity , a classic choice in neural networks. ">SigmoidLayer</a>. <br /></td></tr>
<tr class="separator:a1eb4c2e90dd4807dbfb0806a411a7bea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a52c3183799d44aa9e581992aee502409"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a52c3183799d44aa9e581992aee502409"></a>
vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a52c3183799d44aa9e581992aee502409">sigmoid_bottom_vec_</a></td></tr>
<tr class="memdesc:a52c3183799d44aa9e581992aee502409"><td class="mdescLeft">&#160;</td><td class="mdescRight">bottom vector holder to call the underlying <a class="el" href="classcaffe_1_1Layer.html#a31d00947960a1334be6e45c9a43d8d58" title="Given the bottom blobs, compute the top blobs and the loss. ">SigmoidLayer::Forward</a> <br /></td></tr>
<tr class="separator:a52c3183799d44aa9e581992aee502409"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af6719c9685fcf910129db20cceb47be5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af6719c9685fcf910129db20cceb47be5"></a>
vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#af6719c9685fcf910129db20cceb47be5">sigmoid_top_vec_</a></td></tr>
<tr class="memdesc:af6719c9685fcf910129db20cceb47be5"><td class="mdescLeft">&#160;</td><td class="mdescRight">top vector holder to call the underlying <a class="el" href="classcaffe_1_1Layer.html#a31d00947960a1334be6e45c9a43d8d58" title="Given the bottom blobs, compute the top blobs and the loss. ">SigmoidLayer::Forward</a> <br /></td></tr>
<tr class="separator:af6719c9685fcf910129db20cceb47be5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_attribs_classcaffe_1_1Layer"><td colspan="2" onclick="javascript:toggleInherit('pro_attribs_classcaffe_1_1Layer')"><img src="closed.png" alt="-"/>&#160;Protected Attributes inherited from <a class="el" href="classcaffe_1_1Layer.html">caffe::Layer&lt; Dtype &gt;</a></td></tr>
<tr class="memitem:a7ed12bb2df25c887e41d7ea9557fc701 inherit pro_attribs_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">LayerParameter&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a7ed12bb2df25c887e41d7ea9557fc701">layer_param_</a></td></tr>
<tr class="separator:a7ed12bb2df25c887e41d7ea9557fc701 inherit pro_attribs_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8073fcf2c139b47eb99ce71b346b1321 inherit pro_attribs_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">vector&lt; shared_ptr&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a><br class="typebreak" />
&lt; Dtype &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a8073fcf2c139b47eb99ce71b346b1321">blobs_</a></td></tr>
<tr class="separator:a8073fcf2c139b47eb99ce71b346b1321 inherit pro_attribs_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd4a05def9ff3b42ad72404210613ef7 inherit pro_attribs_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">vector&lt; bool &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#acd4a05def9ff3b42ad72404210613ef7">param_propagate_down_</a></td></tr>
<tr class="separator:acd4a05def9ff3b42ad72404210613ef7 inherit pro_attribs_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af6d347229a139500994e7a926c680486 inherit pro_attribs_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">vector&lt; Dtype &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#af6d347229a139500994e7a926c680486">loss_</a></td></tr>
<tr class="separator:af6d347229a139500994e7a926c680486 inherit pro_attribs_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3>template&lt;typename Dtype&gt;<br />
class caffe::SigmoidCrossEntropyLossLayer&lt; Dtype &gt;</h3>

<p>Computes the cross-entropy (logistic) loss <img class="formulaInl" alt="$ E = \frac{-1}{n} \sum\limits_{n=1}^N \left[ p_n \log \hat{p}_n + (1 - p_n) \log(1 - \hat{p}_n) \right] $" src="form_57.png"/>, often used for predicting targets interpreted as probabilities. </p>
<p>This layer is implemented rather than separate <a class="el" href="classcaffe_1_1SigmoidLayer.html" title="Sigmoid function non-linearity , a classic choice in neural networks. ">SigmoidLayer</a> + CrossEntropyLayer as its gradient computation is more numerically stable. At test time, this layer can be replaced simply by a <a class="el" href="classcaffe_1_1SigmoidLayer.html" title="Sigmoid function non-linearity , a classic choice in neural networks. ">SigmoidLayer</a>.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">bottom</td><td>input <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> vector (length 2)<ol type="1">
<li><img class="formulaInl" alt="$ (N \times C \times H \times W) $" src="form_2.png"/> the scores <img class="formulaInl" alt="$ x \in [-\infty, +\infty]$" src="form_58.png"/>, which this layer maps to probability predictions <img class="formulaInl" alt="$ \hat{p}_n = \sigma(x_n) \in [0, 1] $" src="form_59.png"/> using the sigmoid function <img class="formulaInl" alt="$ \sigma(.) $" src="form_60.png"/> (see <a class="el" href="classcaffe_1_1SigmoidLayer.html" title="Sigmoid function non-linearity , a classic choice in neural networks. ">SigmoidLayer</a>).</li>
<li><img class="formulaInl" alt="$ (N \times C \times H \times W) $" src="form_2.png"/> the targets <img class="formulaInl" alt="$ y \in [0, 1] $" src="form_61.png"/> </li>
</ol>
</td></tr>
    <tr><td class="paramname">top</td><td>output <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> vector (length 1)<ol type="1">
<li><img class="formulaInl" alt="$ (1 \times 1 \times 1 \times 1) $" src="form_28.png"/> the computed cross-entropy loss: <img class="formulaInl" alt="$ E = \frac{-1}{n} \sum\limits_{n=1}^N \left[ p_n \log \hat{p}_n + (1 - p_n) \log(1 - \hat{p}_n) \right] $" src="form_57.png"/> </li>
</ol>
</td></tr>
  </table>
  </dd>
</dl>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a class="anchor" id="af43a48c97cfcc6c3339f99e802797c8d"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html">caffe::SigmoidCrossEntropyLossLayer</a>&lt; Dtype &gt;::Backward_cpu </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;&#160;</td>
          <td class="paramname"><em>top</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; bool &gt; &amp;&#160;</td>
          <td class="paramname"><em>propagate_down</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; *&#160;</td>
          <td class="paramname"><em>bottom</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes the sigmoid cross-entropy loss error gradient w.r.t. the predictions. </p>
<p>Gradients cannot be computed with respect to the target inputs (bottom[1]), so this method ignores bottom[1] and requires !propagate_down[1], crashing if propagate_down[1] is set.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">top</td><td>output <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> vector (length 1), providing the error gradient with respect to the outputs<ol type="1">
<li><img class="formulaInl" alt="$ (1 \times 1 \times 1 \times 1) $" src="form_28.png"/> This <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a>'s diff will simply contain the loss_weight* <img class="formulaInl" alt="$ \lambda $" src="form_70.png"/>, as <img class="formulaInl" alt="$ \lambda $" src="form_70.png"/> is the coefficient of this layer's output <img class="formulaInl" alt="$\ell_i$" src="form_71.png"/> in the overall <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a> loss <img class="formulaInl" alt="$ E = \lambda_i \ell_i + \mbox{other loss terms}$" src="form_72.png"/>; hence <img class="formulaInl" alt="$ \frac{\partial E}{\partial \ell_i} = \lambda_i $" src="form_73.png"/>. (*Assuming that this top <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> is not used as a bottom (input) by any other layer of the <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a>.) </li>
</ol>
</td></tr>
    <tr><td class="paramname">propagate_down</td><td>see <a class="el" href="classcaffe_1_1Layer.html#a38823aa5348f83afd589ec3ac954657e" title="Given the top blob error gradients, compute the bottom blob error gradients. ">Layer::Backward</a>. propagate_down[1] must be false as gradient computation with respect to the targets is not implemented. </td></tr>
    <tr><td class="paramname">bottom</td><td>input <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> vector (length 2)<ol type="1">
<li><img class="formulaInl" alt="$ (N \times C \times H \times W) $" src="form_2.png"/> the predictions <img class="formulaInl" alt="$x$" src="form_81.png"/>; Backward computes diff <img class="formulaInl" alt="$ \frac{\partial E}{\partial x} = \frac{1}{n} \sum\limits_{n=1}^N (\hat{p}_n - p_n) $" src="form_82.png"/></li>
<li><img class="formulaInl" alt="$ (N \times 1 \times 1 \times 1) $" src="form_36.png"/> the labels &ndash; ignored as we can't compute their error gradients </li>
</ol>
</td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classcaffe_1_1Layer.html#a223d932dacb7ff4c010e982f57e775b6">caffe::Layer&lt; Dtype &gt;</a>.</p>

</div>
</div>
<a class="anchor" id="aaf5a9f893661766ca7987ed748027e41"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html">caffe::SigmoidCrossEntropyLossLayer</a>&lt; Dtype &gt;::Forward_cpu </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;&#160;</td>
          <td class="paramname"><em>bottom</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; *&#160;</td>
          <td class="paramname"><em>top</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes the cross-entropy (logistic) loss <img class="formulaInl" alt="$ E = \frac{-1}{n} \sum\limits_{n=1}^N \left[ p_n \log \hat{p}_n + (1 - p_n) \log(1 - \hat{p}_n) \right] $" src="form_57.png"/>, often used for predicting targets interpreted as probabilities. </p>
<p>This layer is implemented rather than separate <a class="el" href="classcaffe_1_1SigmoidLayer.html" title="Sigmoid function non-linearity , a classic choice in neural networks. ">SigmoidLayer</a> + CrossEntropyLayer as its gradient computation is more numerically stable. At test time, this layer can be replaced simply by a <a class="el" href="classcaffe_1_1SigmoidLayer.html" title="Sigmoid function non-linearity , a classic choice in neural networks. ">SigmoidLayer</a>.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">bottom</td><td>input <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> vector (length 2)<ol type="1">
<li><img class="formulaInl" alt="$ (N \times C \times H \times W) $" src="form_2.png"/> the scores <img class="formulaInl" alt="$ x \in [-\infty, +\infty]$" src="form_58.png"/>, which this layer maps to probability predictions <img class="formulaInl" alt="$ \hat{p}_n = \sigma(x_n) \in [0, 1] $" src="form_59.png"/> using the sigmoid function <img class="formulaInl" alt="$ \sigma(.) $" src="form_60.png"/> (see <a class="el" href="classcaffe_1_1SigmoidLayer.html" title="Sigmoid function non-linearity , a classic choice in neural networks. ">SigmoidLayer</a>).</li>
<li><img class="formulaInl" alt="$ (N \times C \times H \times W) $" src="form_2.png"/> the targets <img class="formulaInl" alt="$ y \in [0, 1] $" src="form_61.png"/> </li>
</ol>
</td></tr>
    <tr><td class="paramname">top</td><td>output <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> vector (length 1)<ol type="1">
<li><img class="formulaInl" alt="$ (1 \times 1 \times 1 \times 1) $" src="form_28.png"/> the computed cross-entropy loss: <img class="formulaInl" alt="$ E = \frac{-1}{n} \sum\limits_{n=1}^N \left[ p_n \log \hat{p}_n + (1 - p_n) \log(1 - \hat{p}_n) \right] $" src="form_57.png"/> </li>
</ol>
</td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classcaffe_1_1Layer.html#a7157e270d38711581246bea58ac77a4f">caffe::Layer&lt; Dtype &gt;</a>.</p>

</div>
</div>
<a class="anchor" id="a995f9869f2167df152cdec773b53bd90"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html">caffe::SigmoidCrossEntropyLossLayer</a>&lt; Dtype &gt;::LayerSetUp </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;&#160;</td>
          <td class="paramname"><em>bottom</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; *&#160;</td>
          <td class="paramname"><em>top</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Does layer-specific setup: your layer should implement this. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">bottom</td><td>the preshaped input blobs, whose data fields store the input data for this layer </td></tr>
    <tr><td class="paramname">top</td><td>the allocated but unshaped output blobs, to be initialized by LayerSetUp</td></tr>
  </table>
  </dd>
</dl>
<p>This method should be used to do layer-specific setup. At a minimum, this includes reshaping the empty top blobs to the shape as dictated by the shapes of the bottom blobs and any relevant parameters from the <code>layer_param_</code>. </p>

<p>Reimplemented from <a class="el" href="classcaffe_1_1LossLayer.html#a00f614a20793dcd2a70d93ac0c0a053a">caffe::LossLayer&lt; Dtype &gt;</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>include/caffe/<a class="el" href="loss__layers_8hpp_source.html">loss_layers.hpp</a></li>
<li>src/caffe/layers/sigmoid_cross_entropy_loss_layer.cpp</li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri Sep 5 2014 10:31:47 for Caffe by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.8
</small></address>
</body>
</html>
